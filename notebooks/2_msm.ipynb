{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5609c9b",
   "metadata": {},
   "source": [
    "# 2. LP Model for Finding a Single MSM Plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1e1cc",
   "metadata": {},
   "source": [
    "This is the Julia code for the MATH271 class at Carleton College in Spring 2025 term with Rob Thompson.\n",
    "\n",
    "Final Project: Understanding Breast Cancer Diagnosis and Prognosis via Linear Programming\n",
    "Authors: Palmy Klangsathorn and Angelina Kong\n",
    "Date: 06/05/2025\n",
    "\n",
    "This project explores the application of linear programming techniques to the problem of breast cancer diagnosis and prognosis. We will utilize the Wisconsin Breast Cancer Diagnostic (WBCD) dataset to build and evaluate a predictive model. Our approach will focus on formulating the classification task as a linear program, contrasting it with traditional methods, and analyzing its performance through various statistical metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581054e1",
   "metadata": {},
   "source": [
    "Moreover, we reproduced the Multisurface Method (MSM) and the Multisurface Method Tree (MSM-T) to classify whether a tumor is malignant or benign. The MSM uses an LP model that constructs multiple series of separating planes in a space that divides the data into being either malignant or benign. To do this, let any two points be linearly separable; a plane will be placed between them. Each plane is found by solving a LP problem where the objective is to create the largest distance between the plane and the data points. If there is a case where the two points are not linearly separable, the MSM-T is introduced. MSM-T can construct a plane that will minimize the average distance of misclassified points to the plane, which reduces the number of misclassified points. Due to this, the MSM-T will classify breast cancer samples into being malignant or benign accurately from its use of a decision tree to classify the new points. Thus, MSM and MSM-T produces an interpretable and efficient classification of malignant and benign tumors.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function read the dataset which is a text file and make a dictionary of the dataset\n",
    "function read_to_dict(file_path::String)\n",
    "  data_dict = Dict{String, Vector{Any}}()\n",
    "  try\n",
    "      open(file_path, \"r\") do io\n",
    "          for line in eachline(io)\n",
    "              # split each element in the line by comma\n",
    "              elements = split(line, ',')\n",
    "\n",
    "              if isempty(elements) || all(isempty, elements)\n",
    "                  continue\n",
    "              end\n",
    "\n",
    "              # the first element is the key and the rest form the list\n",
    "              key = String(strip(elements[1]))\n",
    "\n",
    "              # For 'wdbc.data', the first element is an ID, the second is 'M' or 'B' (diagnosis),\n",
    "              # and the rest are floating-point numbers.\n",
    "              data_list = Vector{Any}()\n",
    "              push!(data_list, String(strip(elements[2]))) # diagnosis 'M' or 'B'\n",
    "              for i in 3:length(elements)\n",
    "                  val_str = strip(elements[i])\n",
    "                  if !isempty(val_str)\n",
    "                      try\n",
    "                          push!(data_list, parse(Float64, val_str))\n",
    "                      catch\n",
    "                          push!(data_list, val_str)\n",
    "                      end\n",
    "                  end\n",
    "              end\n",
    "              data_dict[key] = data_list\n",
    "          end\n",
    "      end\n",
    "  catch e\n",
    "      if isa(e, SystemError) && e.errnum == Base.UV_ENOENT\n",
    "          println(\"Error: File not found\")\n",
    "      else\n",
    "          rethrow(e)\n",
    "      end\n",
    "  end\n",
    "  return data_dict\n",
    "end\n",
    "\n",
    "# our dataset\n",
    "file_path = \"wdbc.data\"\n",
    "wdbc_data = read_to_dict(file_path)\n",
    "println(\"Number of entries in dictionary: $(length(wdbc_data))\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# check check\n",
    "specific_key = \"848406\" \n",
    "if haskey(wdbc_data, specific_key)\n",
    "    println(\"\\nData for key '$specific_key':\")\n",
    "    println(wdbc_data[specific_key])\n",
    "else\n",
    "    println(\"\\nKey '$specific_key' not found in the dictionary.\")\n",
    "end\n",
    "\n",
    "# columns info\n",
    "col_names = [\n",
    "    \"ID\", \"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "\n",
    "print(\"\\nThere are  $(length(col_names)) columns\")\n",
    "print(\"\\nThere are  $(length(col_names)-2) features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Prepocessing\n",
    "\n",
    "using DataFrames\n",
    "\n",
    "# We need to create a DataFrame because it provides a structured and efficient way\n",
    "# to store and manipulate tabular data. It also allows us to apply common data operations \n",
    "# like filtering, grouping, and summarizing.\n",
    "# convert all column names to Symbols, which is the standard for DataFrames\n",
    "column_names = Symbol.(col_names)\n",
    "\n",
    "row_tuples = []\n",
    "for (id, values) in wdbc_data\n",
    "    # create a vector for the current row's values\n",
    "    current_row_values = Vector{Any}([id, values[1]]) # start with ID and Diagnosis\n",
    "    append!(current_row_values, values[2:end]) # append all features\n",
    "\n",
    "    # Create a NamedTuple for the current row\n",
    "    # This maps the column names (Symbols) to their respective values\n",
    "    push!(row_tuples, NamedTuple{Tuple(column_names)}(current_row_values))\n",
    "end\n",
    "\n",
    "# Create the DataFrame\n",
    "df = DataFrame(row_tuples)\n",
    "\n",
    "# Now, we can run our subsequent Julia code on 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ff7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Encode diagnosis: M = 1, B = -1\n",
    "\n",
    "# The 'Diagnosis' column in the original data contains categorical string labels:\n",
    "# \"M\" for malignant and \"B\" for benign tumors.\n",
    "\n",
    "# Most machine learning algorithms require numeric inputs, not strings. \n",
    "# So we need to convert these string labels into numeric values.\n",
    "\n",
    "# In this step, we use the `ifelse.` broadcasting function to perform element-wise conversion:\n",
    "# - If the diagnosis is \"M\" (malignant), we encode it as 1.0\n",
    "# - If the diagnosis is \"B\" (benign), we encode it as -1.0\n",
    "\n",
    "df.Diagnosis = ifelse.(df.Diagnosis .== \"M\", 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72525ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract features and normalize (using StatsBase.zscore)\n",
    "# using Pkg\n",
    "# Pkg.activate(\".\")\n",
    "# Pkg.instantiate()\n",
    "\n",
    "# Pkg.add(\"StatsBase\")\n",
    "using StatsBase \n",
    "using DataFrames\n",
    "\n",
    "# Extract features from 3rd column to end\n",
    "X = Matrix(df[:, 3:end]) \n",
    "y = df.Diagnosis\n",
    "\n",
    "X = zscore(X, 1) # Normalize columns (dims=1 means normalize each column)\n",
    "\n",
    "# Now, X is normalized\n",
    "\n",
    "# By applying zscore(X, 1), we transform each column (feature) of X so that it has a mean of 0 and a standard deviation of 1. \n",
    "# features in the original dataset often have different scales and units (like \"radius\" might be in millimeters, \"area\" in square millimeters,\n",
    "# \"smoothness\" a dimensionless value). Without normalization, features with larger numerical ranges or higher magnitudes would implicitly \n",
    "# contribute more to the distance calculations and objective functions of algorithms. Normalization ensures that all features contribute \n",
    "# proportionally to the model, preventing features with larger scales from dominating the learning process\n",
    "\n",
    "# confirm sizes\n",
    "println(\"\\n--- Checking sizes before shuffleobs ---\")\n",
    "println(\"Size of X (rows, cols): \", size(X))\n",
    "println(\"Length of y (rows): \", length(y))\n",
    "println(\"Are X rows and y length equal? \", size(X, 1) == length(y))\n",
    "println(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae91259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train-test split \n",
    "\n",
    "# using Pkg\n",
    "# Pkg.activate(\".\")\n",
    "# Pkg.instantiate()\n",
    "using MLJBase \n",
    "using Random \n",
    "\n",
    "# get the total number of observations\n",
    "num_observations = size(X, 1)\n",
    "\n",
    "# create a vector of indices\n",
    "indices = collect(1:num_observations)\n",
    "\n",
    "# shuffle the indices in-place\n",
    "Random.shuffle!(indices)\n",
    "\n",
    "# determine split point\n",
    "split_point = floor(Int, num_observations * 0.8)\n",
    "\n",
    "# split the shuffled indices into train and test sets\n",
    "train_indices = indices[1:split_point]\n",
    "test_indices = indices[split_point+1:end]\n",
    "\n",
    "# use these shuffled indices to create your train and test sets\n",
    "X_train = X[train_indices, :]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "X_test = X[test_indices, :]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "y_train_numeric = convert(Vector{Int}, y_train)\n",
    "y_test_numeric = convert(Vector{Int}, y_test)\n",
    "\n",
    "\n",
    "println(\"X_train dimensions: \", size(X_train))\n",
    "println(\"y_train length: \", length(y_train))\n",
    "println(\"X_test dimensions: \", size(X_test))\n",
    "println(\"y_test length: \", length(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using HiGHS \n",
    "using LinearAlgebra \n",
    "using Statistics \n",
    "using Plots \n",
    "using DataFrames \n",
    "using CSV \n",
    "using Random \n",
    "import Pkg; Pkg.add(\"MathOptInterface\")\n",
    "import MathOptInterface as MOI \n",
    "\n",
    "# This function finds one separating plane for a given subset of data\n",
    "function solve_msm_plane_lp(X_subset::Matrix{Float64}, y_subset::Vector{Int64}, C_msm::Float64)\n",
    "    n_subset, d_subset = size(X_subset)\n",
    "\n",
    "    model_msm = JuMP.Model(HiGHS.Optimizer)\n",
    "    set_silent(model_msm)\n",
    "\n",
    "    # Variables\n",
    "    @variable(model_msm, w[1:d_subset])\n",
    "    @variable(model_msm, b)\n",
    "    @variable(model_msm, zeta[1:n_subset] >= 0) # Slack variables for misclassification\n",
    "    @variable(model_msm, rho >= 0) # Margin variable\n",
    "\n",
    "    # Auxiliary variable\n",
    "    @variable(model_msm, t[1:d_subset] >= 0) # Auxiliary variables for absolute values\n",
    "\n",
    "    # Objective: Maximize the margin (rho) while penalizing misclassification (zeta)\n",
    "    @objective(model_msm, Max, rho - C_msm * sum(zeta))\n",
    "\n",
    "\n",
    "    for i in 1:n_subset\n",
    "        @constraint(model_msm, y_subset[i] * (dot(X_subset[i,:], w) + b) >= rho - zeta[i])\n",
    "    end\n",
    "\n",
    "    # linearized L1 norm\n",
    "    for j in 1:d_subset\n",
    "        @constraint(model_msm, w[j] <= t[j])\n",
    "        @constraint(model_msm, w[j] >= -t[j])\n",
    "    end\n",
    "    @constraint(model_msm, sum(t) <= 1.0) # Sum of t_j replaces sum(abs.(w))\n",
    "\n",
    "    optimize!(model_msm)\n",
    "\n",
    "    status = termination_status(model_msm)\n",
    "\n",
    "    if status == MOI.OPTIMAL\n",
    "        return value.(w), value(b), value(rho), status\n",
    "    else\n",
    "        println(\"solve_msm_plane_lp failed with status: $status\")\n",
    "        return zeros(d_subset), 0.0, 0.0, status\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ac2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this orchestrates finding multiple planes\n",
    "function run_msm(X_train::Matrix{Float64}, y_train_numeric::Vector{Int64};\n",
    "                 max_planes::Int=5, C_msm::Float64=1.0, convergence_threshold::Float64=0.01)\n",
    "\n",
    "    all_w = Vector{Vector{Float64}}() \n",
    "    all_b = Vector{Float64}()         \n",
    "    all_rho = Vector{Float64}()  \n",
    "\n",
    "    n_samples = size(X_train, 1)\n",
    "    current_misclassified_indices = collect(1:n_samples)\n",
    "    previous_num_misclassified = n_samples + 1\n",
    "\n",
    "    println(\"\\n--- Starting MSM Training ---\")\n",
    "\n",
    "    for k in 1:max_planes\n",
    "        if isempty(current_misclassified_indices)\n",
    "            println(\"Iteration $k: All points classified. Stopping.\")\n",
    "            break\n",
    "        end\n",
    "\n",
    "        X_subset = X_train[current_misclassified_indices, :]\n",
    "        y_subset = y_train_numeric[current_misclassified_indices]\n",
    "\n",
    "        println(\"Iteration $k: Training plane on $(length(current_misclassified_indices)) misclassified points.\")\n",
    "\n",
    "        w_k, b_k, rho_k, status = solve_msm_plane_lp(X_subset, y_subset, C_msm)\n",
    "\n",
    "        if status != MOI.OPTIMAL\n",
    "            println(\"Iteration $k: solve_msm_plane_lp did not find an optimal solution. Stopping.\")\n",
    "            break \n",
    "        end\n",
    "\n",
    "        push!(all_w, w_k)\n",
    "        push!(all_b, b_k)\n",
    "        push!(all_rho, rho_k)\n",
    "\n",
    "        # Re-evaluate all original training points against the *set of all found planes*\n",
    "        # This is a critical part of MSM: how to define 'misclassified' over multiple planes.\n",
    "        # A simple approach: A point is classified if *any* plane classifies it correctly.\n",
    "        # Otherwise, it remains misclassified.\n",
    "        \n",
    "        y_overall_pred = fill(0, n_samples) # 0 for unclassified, -1 or 1 for classified\n",
    "        for i in 1:n_samples\n",
    "            point_classified = false\n",
    "            for p_idx in 1:length(all_w) # Check against all planes found so far\n",
    "                val = dot(X_train[i,:], all_w[p_idx]) + all_b[p_idx]\n",
    "                \n",
    "                # If the point falls within the margin of this plane, it's not \"clearly\" classified by *this* plane\n",
    "                # For simplicity here, we consider it classified if it's beyond the margin on the correct side\n",
    "                # A more nuanced approach would be needed for a full MSM.\n",
    "                if val > all_rho[p_idx] # Classified as +1 by this plane, outside its margin\n",
    "                    if y_train_numeric[i] == 1\n",
    "                        y_overall_pred[i] = 1 # Correctly classified\n",
    "                        point_classified = true\n",
    "                        break\n",
    "                    end\n",
    "                elseif val < -all_rho[p_idx] # Classified as -1 by this plane, outside its margin\n",
    "                    if y_train_numeric[i] == -1\n",
    "                        y_overall_pred[i] = -1 # Correctly classified\n",
    "                        point_classified = true\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            if !point_classified && y_overall_pred[i] == 0 # If still not classified by any plane\n",
    "                # If it's a misclassified point, keep it in the current_misclassified_indices set.\n",
    "                # For this simplified MSM, a point is \"misclassified\" if it's not correctly classified by any plane yet.\n",
    "                # This logic can be more complex for different MSM variants.\n",
    "                # Here, we mark it as unclassified if no plane correctly pushes it beyond its margin.\n",
    "                # A more precise misclassification check for MSM depends on its specific variant.\n",
    "                # For simplicity, let's say a point is *not* misclassified if *any* plane has successfully pushed it.\n",
    "                # This might be tricky for \"deepest plane\" concepts.\n",
    "                \n",
    "                # Let's simplify: A point is misclassified if for *all* planes, it's not on the correct side beyond the margin.\n",
    "                # Rebuilding misclassified_indices more directly:\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Recalculate current_misclassified_indices based on *all* planes found so far\n",
    "        temp_misclassified_indices = Int[]\n",
    "        for i in 1:n_samples\n",
    "            is_correctly_classified_by_any_plane = false\n",
    "            for p_idx in 1:length(all_w)\n",
    "                val = dot(X_train[i,:], all_w[p_idx]) + all_b[p_idx]\n",
    "                if (y_train_numeric[i] == 1 && val > all_rho[p_idx]) ||\n",
    "                   (y_train_numeric[i] == -1 && val < -all_rho[p_idx])\n",
    "                    is_correctly_classified_by_any_plane = true\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "            if !is_correctly_classified_by_any_plane\n",
    "                push!(temp_misclassified_indices, i)\n",
    "            end\n",
    "        end\n",
    "        current_misclassified_indices = temp_misclassified_indices\n",
    "\n",
    "\n",
    "        num_misclassified = length(current_misclassified_indices)\n",
    "        misclassification_ratio = num_misclassified / n_samples\n",
    "\n",
    "        println(\"Iteration $k Summary:\")\n",
    "        println(\"  Planes found so far: $(length(all_w))\")\n",
    "        println(\"  Current misclassified points: $num_misclassified / $n_samples ($(round(misclassification_ratio*100, digits=2))%)\")\n",
    "\n",
    "        # Convergence criteria\n",
    "        if num_misclassified == 0\n",
    "            println(\"All training points perfectly classified. Stopping.\")\n",
    "            break\n",
    "        end\n",
    "        if misclassification_ratio <= convergence_threshold\n",
    "            println(\"Convergence threshold reached. Stopping.\")\n",
    "            break\n",
    "        end\n",
    "        if num_misclassified >= previous_num_misclassified && k > 1 # No progress\n",
    "            println(\"No further reduction in misclassified points. Stopping.\")\n",
    "            break\n",
    "        end\n",
    "        previous_num_misclassified = num_misclassified\n",
    "    end\n",
    "\n",
    "    println(\"--- MSM Training Finished ---\")\n",
    "    return all_w, all_b, all_rho\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction, classify a new point using multiple planes\n",
    "function predict_msm(x::Vector{Float64}, all_w::Vector{Vector{Float64}}, all_b::Vector{Float64}, all_rho::Vector{Float64})\n",
    "    positive_votes = 0\n",
    "    negative_votes = 0\n",
    "\n",
    "    for k in 1:length(all_w)\n",
    "        w_k = all_w[k]\n",
    "        b_k = all_b[k]\n",
    "        rho_k = all_rho[k]\n",
    "\n",
    "        val = dot(x, w_k) + b_k\n",
    "\n",
    "        if val > rho_k # positive side beyond its margin\n",
    "            positive_votes += 1\n",
    "        elseif val < -rho_k # negative side beyond its margin\n",
    "            negative_votes += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if positive_votes > negative_votes\n",
    "        return 1\n",
    "    elseif negative_votes > positive_votes\n",
    "        return -1\n",
    "    else\n",
    "        return 0 \n",
    "    end\n",
    "end\n",
    "\n",
    "function predict_msm_batch(X::Matrix{Float64}, all_w::Vector{Vector{Float64}}, all_b::Vector{Float64}, all_rho::Vector{Float64})\n",
    "    n_samples = size(X, 1)\n",
    "    y_pred = Vector{Int}(undef, n_samples)\n",
    "    for i in 1:n_samples\n",
    "        y_pred[i] = predict_msm(X[i,:], all_w, all_b, all_rho)\n",
    "    end\n",
    "    return y_pred\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eea442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "\n",
    "function calculate_accuracy(y_true::Vector{Int}, y_pred::Vector{Int})\n",
    "    correct_predictions = sum(y_true .== y_pred)\n",
    "    total_predictions = length(y_true)\n",
    "    return correct_predictions / total_predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d60436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MSM model\n",
    "println(\"\\n--- Running MSM Training on Training Data ---\")\n",
    "all_w_msm, all_b_msm, all_rho_msm = run_msm(X_train, y_train_numeric; max_planes=10, C_msm=0.1)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_msm = predict_msm_batch(X_train, all_w_msm, all_b_msm, all_rho_msm)\n",
    "train_accuracy_msm = calculate_accuracy(y_train_numeric, y_train_pred_msm)\n",
    "println(\"\\nMSM Training Accuracy: $(round(train_accuracy_msm * 100, digits=2))%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "println(\"\\n--- Evaluating MSM on Test Data ---\")\n",
    "y_test_pred_msm = predict_msm_batch(X_test, all_w_msm, all_b_msm, all_rho_msm)\n",
    "\n",
    "test_accuracy_msm = calculate_accuracy(y_test_numeric, y_test_pred_msm)\n",
    "println(\"MSM Test Accuracy: $(round(test_accuracy_msm * 100, digits=2))%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ \n",
    "using CategoricalArrays \n",
    "using Printf \n",
    "\n",
    "println(\"\\n--- Evaluating MSM on Test Data ---\")\n",
    "y_test_pred_msm = predict_msm_batch(X_test, all_w_msm, all_b_msm, all_rho_msm)\n",
    "\n",
    "# --- Confusion Matrix and Classification Metrics for MSM ---\n",
    "\n",
    "# Handling the '0' (uncertain) class from predict_msm_batch:\n",
    "# For standard binary classification metrics, predictions of '0' need to be resolved\n",
    "# into either the positive or negative class. A common strategy is to force them\n",
    "# into a misclassification:\n",
    "# - If true label is Benign (-1/0), and prediction is 0, treat it as a Malignant (1) prediction (False Positive).\n",
    "# - If true label is Malignant (1), and prediction is 0, treat it as a Benign (-1/0) prediction (False Negative).\n",
    "\n",
    "y_test_pred_resolved = [\n",
    "    if pred == -1\n",
    "        0 \n",
    "    elseif pred == 1\n",
    "        1 \n",
    "    else \n",
    "        true_label == -1 ? 1 : 0\n",
    "    end\n",
    "    for (pred, true_label) in zip(y_test_pred_msm, y_test_numeric)\n",
    "]\n",
    "\n",
    "y_test_true_resolved = [label == -1 ? 0 : 1 for label in y_test_numeric]\n",
    "\n",
    "\n",
    "# create CategoricalArrays for MLJ's confusion_matrix\n",
    "y_true_cat = categorical(y_test_true_resolved, levels=[0, 1], ordered=true)\n",
    "y_pred_cat = categorical(y_test_pred_resolved, levels=[0, 1], ordered=true)\n",
    "\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = MLJ.confusion_matrix(y_pred_cat, y_true_cat)\n",
    "println(\"\\n--- MSM Confusion Matrix (Test Data) ---\")\n",
    "# The rows represent predicted classes, and columns represent true classes.\n",
    "# For levels [0, 1]:\n",
    "# conf_matrix[1, 1] is True Negatives (Actual 0, Predicted 0)\n",
    "# conf_matrix[2, 2] is True Positives (Actual 1, Predicted 1)\n",
    "# conf_matrix[1, 2] is False Negatives (Actual 1, Predicted 0) - Type II error (Missed Malignant)\n",
    "# conf_matrix[2, 1] is False Positives (Actual 0, Predicted 1) - Type I error (False Alarm Malignant)\n",
    "println(conf_matrix)\n",
    "\n",
    "# Extract core components from the confusion matrix\n",
    "true_neg = conf_matrix[1, 1] # Actual 0, Predicted 0 (Top-left)\n",
    "false_pos = conf_matrix[2, 1] # Actual 0, Predicted 1 (Bottom-left)\n",
    "false_neg = conf_matrix[1, 2] # Actual 1, Predicted 0 (Top-right)\n",
    "true_pos = conf_matrix[2, 2] # Actual 1, Predicted 1 (Bottom-right)\n",
    "\n",
    "println(\"\\n--- MSM Classification Metrics (Test Data) ---\")\n",
    "# https://juliaai.github.io/StatisticalMeasures.jl/dev/confusion_matrices/\n",
    "# Accuracy: (TP + TN) / Total\n",
    "total_samples = true_pos + true_neg + false_pos + false_neg\n",
    "accuracy_val = total_samples > 0 ? (true_pos + true_neg) / total_samples : 0.0\n",
    "println(@sprintf \"Accuracy:    %.4f\" accuracy_val)\n",
    "\n",
    "# Precision: TP / (TP + FP) - Of all predicted positives, how many were actually positive?\n",
    "precision_val = (true_pos + false_pos) > 0 ? true_pos / (true_pos + false_pos) : 0.0\n",
    "println(@sprintf \"Precision:   %.4f\" precision_val)\n",
    "\n",
    "# Recall (Sensitivity): TP / (TP + FN) - Of all actual positives, how many were correctly identified?\n",
    "recall_val = (true_pos + false_neg) > 0 ? true_pos / (true_pos + false_neg) : 0.0\n",
    "println(@sprintf \"Recall:      %.4f\" recall_val)\n",
    "\n",
    "# F1-Score: 2 * (Precision * Recall) / (Precision + Recall) - Harmonic mean of Precision and Recall\n",
    "f1_val = (precision_val + recall_val) > 0 ? 2 * (precision_val * recall_val) / (precision_val + recall_val) : 0.0\n",
    "println(@sprintf \"F1-Score:    %.4f\" f1_val)\n",
    "\n",
    "# Specificity: TN / (TN + FP) - Of all actual negatives, how many were correctly identified?\n",
    "specificity_val = (true_neg + false_pos) > 0 ? true_neg / (true_neg + false_pos) : 0.0\n",
    "println(@sprintf \"Specificity: %.4f\" specificity_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad06d38",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db031630",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "col_names = [\n",
    "    \"ID\", \"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "\n",
    "feature_names = col_names[3:end]\n",
    "\n",
    "\n",
    "println(\"\\n--- Plotting Feature Coefficients for each MSM Plane ---\")\n",
    "for (idx, w_plane) in enumerate(all_w_msm)\n",
    "    annotations = []\n",
    " \n",
    "    max_abs_coeff_plane = isempty(w_plane) ? 0.0 : maximum(abs.(w_plane))\n",
    "\n",
    "\n",
    "    annotation_fontsize = 5\n",
    "    inside_margin_factor = 0.8\n",
    "    \n",
    "    min_coeff_for_inside_text = max_abs_coeff_plane * 0.1 \n",
    "    \n",
    "    if iszero(max_abs_coeff_plane)\n",
    "        outside_margin = 0.05\n",
    "        min_coeff_for_inside_text = 0.01\n",
    "    else\n",
    "        outside_margin = max_abs_coeff_plane * 0.05\n",
    "    end\n",
    "\n",
    "    for i in 1:length(w_plane)\n",
    "        coeff_value = w_plane[i]\n",
    "        text_label = @sprintf \"%.2f\" coeff_value \n",
    "        \n",
    "        y_pos = 0.0\n",
    "\n",
    "        if abs(coeff_value) > min_coeff_for_inside_text\n",
    "            if coeff_value > 0\n",
    "                y_pos = coeff_value * inside_margin_factor \n",
    "            else \n",
    "                y_pos = coeff_value * inside_margin_factor \n",
    "            end\n",
    "        else\n",
    "            \n",
    "            if coeff_value > 0\n",
    "                y_pos = coeff_value + outside_margin\n",
    "            elseif coeff_value < 0\n",
    "                y_pos = coeff_value - outside_margin\n",
    "            else\n",
    "                y_pos = outside_margin \n",
    "            end\n",
    "        end\n",
    "        push!(annotations, (i, y_pos, Plots.text(text_label, annotation_fontsize)))\n",
    "    end\n",
    "\n",
    "    # the bar plot with the generated annotations\n",
    "    p_coeffs_msm = bar(1:length(w_plane), w_plane,\n",
    "                       title=\"MSM Plane $(idx) Feature Coefficients\",\n",
    "                       xlabel=\"Feature Name\",\n",
    "                       ylabel=\"Coefficient Value\",\n",
    "                       xticks=(1:length(feature_names), feature_names), \n",
    "                       xrotation=90, \n",
    "                       legend=false,\n",
    "                       size=(1200, 700), \n",
    "                       bottom_margin=15Plots.mm, \n",
    "                       left_margin=10Plots.mm, \n",
    "                       annotations=annotations) \n",
    "    \n",
    "    display(p_coeffs_msm)\n",
    "    savefig(p_coeffs_msm, \"images/msm_plane_$(idx)_coeffs.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using MultivariateStats # this is for PCA\n",
    "using StatsPlots \n",
    "\n",
    "function predict_msm_score(x_new::Vector{Float64}, all_w_msm::Vector{Vector{Float64}}, all_b_msm::Vector{Float64})\n",
    "    if isempty(all_w_msm) || isempty(all_b_msm) || length(x_new) != length(all_w_msm[1])\n",
    "        return NaN \n",
    "    end\n",
    "    return dot(x_new, all_w_msm[1]) + all_b_msm[1]\n",
    "end\n",
    "\n",
    "\n",
    "function predict_msm_class(X::Matrix{Float64}, all_w_msm::Vector{Vector{Float64}}, all_b_msm::Vector{Float64})\n",
    "    n_samples = size(X, 1)\n",
    "    predictions = Vector{Int}(undef, n_samples)\n",
    "\n",
    "    if isempty(all_w_msm) || isempty(all_b_msm)\n",
    "        return fill(-99, n_samples)\n",
    "    end\n",
    "\n",
    "    for i in 1:n_samples\n",
    "        x_row = X[i, :]\n",
    "        score = dot(x_row, all_w_msm[1]) + all_b_msm[1]\n",
    "        predictions[i] = score > 0 ? 1 : -1\n",
    "    end\n",
    "    return predictions\n",
    "end\n",
    "\n",
    "#  PCA-reduced to 2 features\n",
    "\n",
    "d = size(X_train, 2) \n",
    "\n",
    "if d == 2\n",
    "    println(\"\\n--- Generating 2D Decision Boundary Plot for MSM ---\")\n",
    "\n",
    "    x_min, x_max = extrema(X_train[:, 1])\n",
    "    y_min, y_max = extrema(X_train[:, 2])\n",
    "\n",
    "    x_buffer = (x_max - x_min) * 0.1\n",
    "    y_buffer = (y_max - y_min) * 0.1\n",
    "    plot_x_min, plot_x_max = x_min - x_buffer, x_max + x_buffer\n",
    "    plot_y_min, plot_y_max = y_min - y_buffer, y_max + y_buffer\n",
    "\n",
    "    num_grid_points = 100\n",
    "    test_range_x = range(plot_x_min, stop=plot_x_max, length=num_grid_points)\n",
    "    test_range_y = range(plot_y_min, stop=plot_y_max, length=num_grid_points)\n",
    "\n",
    "    Z = Matrix{Float64}(undef, num_grid_points, num_grid_points)\n",
    "    for (i, x_val) in enumerate(test_range_x)\n",
    "        for (j, y_val) in enumerate(test_range_y)\n",
    "            grid_point = [x_val, y_val]\n",
    "            Z[i, j] = predict_msm_score(grid_point, all_w_msm, all_b_msm)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    p_2d_msm = plot(;\n",
    "        xlim=(plot_x_min, plot_x_max),\n",
    "        ylim=(plot_y_min, plot_y_max),\n",
    "        aspect_ratio=1,\n",
    "        title=\"MSM Decision Boundaries (2D Features)\",\n",
    "        xlabel=\"Feature 1\",\n",
    "        ylabel=\"Feature 2\",\n",
    "        legend=:outertopright\n",
    "    )\n",
    "\n",
    "    contourf!(\n",
    "        p_2d_msm,\n",
    "        test_range_x,\n",
    "        test_range_y,\n",
    "        Z;\n",
    "        levels=[0], \n",
    "        color=cgrad(:redsblues), \n",
    "        alpha=0.7,\n",
    "        colorbar_title=\"Predicted Score\",\n",
    "        label=\"\", \n",
    "    )\n",
    "\n",
    "    X1 = X_train[y_train_numeric .== -1, :]\n",
    "    X2 = X_train[y_train_numeric .== 1, :]\n",
    "\n",
    "    scatter!(p_2d_msm, X1[:, 1], X1[:, 2]; color=:red, label=\"Class -1 (Benign)\", markershape=:circle, markersize=5)\n",
    "    scatter!(p_2d_msm, X2[:, 1], X2[:, 2]; color=:blue, label=\"Class 1 (Malignant)\", markershape=:xcross, markersize=5)\n",
    "\n",
    "    if !isempty(all_w_msm) && !isempty(all_b_msm)\n",
    "        for (idx, w_plane) in enumerate(all_w_msm)\n",
    "            b_plane = all_b_msm[idx]\n",
    "            if length(w_plane) == 2 # it's a 2D plane for plotting its line\n",
    "                # w[1]*x + w[2]*y + b = 0\n",
    "                # y = (-w[1]*x - b) / w[2]\n",
    "                if abs(w_plane[2]) > 1e-6 \n",
    "                    plot!(p_2d_msm, test_range_x, x -> (-w_plane[1]*x - b_plane) / w_plane[2],\n",
    "                          label=\"Plane $(idx)\", linestyle=:dot, linewidth=2, color=:black)\n",
    "                else\n",
    "                    vline!(p_2d_msm, [-b_plane / w_plane[1]], label=\"Plane $(idx)\", linestyle=:dot, linewidth=2, color=:black)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    display(p_2d_msm)\n",
    "    savefig(p_2d_msm, \"images/msm_2d_decision_boundaries.png\")\n",
    "    println(\"Displayed 'MSM Decision Boundaries (2D)' plot.\")\n",
    "\n",
    "else\n",
    "    # ig Data is high-dimensional (d > 2), use PCA for 2D visualization\n",
    "    println(\"\\n--- Attempting 2D Visualization via PCA for MSM ---\")\n",
    "\n",
    "    # Prepare data for PCA: MultivariateStats.jl expects (features x samples)\n",
    "    X_train_for_pca = permutedims(X_train)\n",
    "\n",
    "    # Perform PCA to reduce to 2 dimensions\n",
    "    M = MultivariateStats.fit(MultivariateStats.PCA, X_train_for_pca; maxoutdim=2)\n",
    "\n",
    "    # Transform training data to the 2D PCA space\n",
    "    X_train_pca = MultivariateStats.transform(M, X_train_for_pca) # Result will be 2 x n_samples\n",
    "\n",
    "    # Transpose back for plotting: (n_samples x 2)\n",
    "    X_train_pca_plot = permutedims(X_train_pca)\n",
    "\n",
    "    # Determine plot limits from the transformed data\n",
    "    x_min_pca, x_max_pca = extrema(X_train_pca_plot[:, 1])\n",
    "    y_min_pca, y_max_pca = extrema(X_train_pca_plot[:, 2])\n",
    "\n",
    "    x_buffer_pca = (x_max_pca - x_min_pca) * 0.1\n",
    "    y_buffer_pca = (y_max_pca - y_min_pca) * 0.1\n",
    "    plot_x_min_pca, plot_x_max_pca = x_min_pca - x_buffer_pca, x_max_pca + x_buffer_pca\n",
    "    plot_y_min_pca, plot_y_max_pca = y_min_pca - y_buffer_pca, y_max_pca + y_buffer_pca\n",
    "\n",
    "\n",
    "    # --- Plot 2a: True Labels in PCA Space ---\n",
    "    p_pca_true = plot(;\n",
    "        xlim=(plot_x_min_pca, plot_x_max_pca),\n",
    "        ylim=(plot_y_min_pca, plot_y_max_pca),\n",
    "        aspect_ratio=1,\n",
    "        title=\"MSM Data in PCA Space (True Labels)\",\n",
    "        xlabel=\"Principal Component 1\",\n",
    "        ylabel=\"Principal Component 2\",\n",
    "        legend=:outertopright\n",
    "    )\n",
    "\n",
    "    # Separate data points by true class for plotting\n",
    "    X1_pca = X_train_pca_plot[y_train_numeric .== -1, :]\n",
    "    X2_pca = X_train_pca_plot[y_train_numeric .== 1, :]\n",
    "\n",
    "    scatter!(p_pca_true, X1_pca[:, 1], X1_pca[:, 2]; color=:red, label=\"Class -1 (Benign)\", markershape=:circle, markersize=5)\n",
    "    scatter!(p_pca_true, X2_pca[:, 1], X2_pca[:, 2]; color=:blue, label=\"Class 1 (Malignant)\", markershape=:xcross, markersize=5)\n",
    "\n",
    "    display(p_pca_true)\n",
    "    savefig(p_pca_true, \"images/msm_pca_true_labels.png\")\n",
    "    println(\"Displayed 'MSM Data in PCA Space (True Labels)' plot.\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
